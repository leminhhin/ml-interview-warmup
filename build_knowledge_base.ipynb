{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "\n",
    "# https://docs.trychroma.com/troubleshooting#sqlite\n",
    "# __import__('pysqlite3')\n",
    "# import sys\n",
    "# sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "import os\n",
    "import pinecone\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 28 pages found.\n",
      "Total 3377 chunked documents.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://lilianweng.github.io/\"\n",
    "loader = RecursiveUrlLoader(url=url, max_depth=2, extractor=lambda x: Soup(x, \"html.parser\").text)\n",
    "docs = loader.load()\n",
    "print(f'Total {len(docs)} pages found.')\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=256, chunk_overlap=30)\n",
    "\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(docs)\n",
    "print(f'Total {len(docs)} chunked documents.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_ENV,  # next to api key in console\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_name = \"ml-interview-warmup\"\n",
    "\n",
    "# First, check if our index already exists. If it doesn't, we create it\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # we create a new index\n",
    "    pinecone.create_index(\n",
    "      name=index_name,\n",
    "      metric='cosine',\n",
    "      dimension=384  \n",
    ")\n",
    "\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "db = Pinecone.from_documents(docs, embedding_function, index_name=index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " year    = \"2023\",\n",
      "  month   = \"Jun\",\n",
      "  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
      "}\n",
      "References#\n",
      "[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.\" NeurIPS 2022\n",
      "[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.\" arXiv preprint arXiv:2305.10601 (2023).\n",
      "[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\n",
      "“ arXiv preprint arXiv:2302.02676 (2023).\n",
      "[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\n",
      "[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.\" ICLR 2023.\n",
      "[6] Google Blog. “Announcing ScaNN:\n"
     ]
    }
   ],
   "source": [
    "query = \"ways to prompt large language models?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[1].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
